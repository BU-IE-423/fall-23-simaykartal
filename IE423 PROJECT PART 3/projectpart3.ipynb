{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>IE 423 PROJECT PART 3</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Melih Kocakaplan 2019402210</h5>\n",
    "<h5>Simay Kartal 2019402072</h5>\n",
    "<h5>Demet Şeker 2019402141</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>INTRODUCTION</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linen is a fabric woven from fibers obtained from the stem of the flax plant (obtained from the Linum usitatissimum plant). Linen is one of the oldest fibers in the world and has been used for thousands of years. It makes clothes, bags, towels, tablecloths and more. The main features of linen are that it is strong and durable, airy, absorbent, and non-allergic. It is widely used in clothes, especially in summer. Monitoring linen processing is important because it can help improve quality and yield. Flax processing consists of many stages such as planting the seeds, harvesting, separating the fibers, and weaving the fabric. At each stage, errors can occur that can affect quality and efficiency. Visuals can be used at every stage of the linen processing process to detect and prevent these errors. In the field of quality control, images can be used to evaluate the quality of flax fibers and fabric. This can help detect defects and improve quality. For example, defective flax fibers or fabric may reduce the quality of the product. This can reduce customer satisfaction and increase product returns. It can also help identify bottlenecks and optimize the process while increasing the efficiency of linen production. Apart from these, detecting defective linens using visuals can also reduce unnecessary labor, material and energy costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![linen](linen.jpg) ![linen](linen2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>DEFECT DETECTION IN THE LITERATURE</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality engineers need to be responsible for every stage of a process. They must be able to cover every stage and detect defects. This defect detection process can be considered broadly both during and after production. When the necessary research was done, it was found that observations were made at every stage of production. Image processing techniques are useful for these kinds of problems.\n",
    "\"The Thresholding\" technique basically assigns some values to the pixel intensity values. It determines a threshold value related to the process and assigns the pixels that are above the threshold one value and the below ones another value. It can separate the background and the main picture clearly to visualize. On the other hand, \"The Mathematical Morphology\" uses a different and more detailed technique. It has some main titles like dilation, erosion, opening, and closing. These are the most used features of this technique. What they do is basically make pixels or figures larger or smaller, wider or narrower. They are used by quality engineers because sometimes the images can be not sharp or can fail while zooming or something else. Patterns and advanced deep learning techniques are also used for the steps of image processing, which are more complicated than the above ones.\n",
    "The defect detection techniques that are used more in literature can be summarized as in the figure. There are also some statistical methods which are not mentioned above. Those methods are the most related ones to this project’s aim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![şema](detec.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research on linen process monitoring using image processing explores various applications like fabric quality assessment, washing cycle optimization, soiling detection, and most importantly, defect identification. Techniques like Gabor filters, fuzzy logic, color analysis, and edge detection have been employed with success, but challenges like lighting variations, fabric complexity, and computational limitations persist. Future directions involve deep learning integration, edge computing, and standardization for improved accuracy, real-time feedback, and wider applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- A Baseline Defect Detection Approach from a Statistical Data Analysis Perspective</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all stages of the project, a grayscale image is required to numerically represent the image that will be worked on. By converting it into grayscale, a matrix of size that is the same as the pixel size of the original image is obtained and this matrix acts as a base for all the calculations carried out on the image processing strategies. After the image to be studied was gray-scaled, a histogram of the resulting matrix (512x512) pixels was plotted so that the distribution of the pixel values can be interpreted. When this histogram was evaluated, the pixels' distribution was considered as a \"normal distribution\". After the decision of the distribution, the parameters of normal distribution, mean and variance, are estimated as 84.39880752563477 and 30.7885304576133, respectively. The Threshold value was taken as 0.001 as asked in the question and the areas outside the upper bound and lower bound were painted as black. In this way, it was aimed to identify out-of-control points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](1.png)\n",
    "\n",
    "*Modified image for 0.001 probability limits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visual differences and the decomposability of the defective points were examined in the resulting image. The out-of-control areas were painted black so that they were visible in the picture. Then the model was tested a number of times with boundaries of different sizes, and a more undesirable image was created as the boundaries of the acceptance region enlarged since the likelihood of a point to be classified as out-of-control was reduced. When the threshold is set as 0.0005, Type 1 error probability decreases and accordingly, Type 2 error probability increases, meaning that at the expense of obtaining less signals of defect, we are placed at a safer point. This explains the reason for the selected threshold. Subsequently, upper and lower bounds were narrowed further and defects became more obvious. This has been the most desired upcoming result so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](2.png)\n",
    "\n",
    "*Modified image for 0.0005 probability limits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](3.png)\n",
    "\n",
    "*Modified image for 0.001 probability limits with better visualization via smaller control limits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterward, the window size approach was used. For this approach, patches size 51x51 were examined. The underlying distribution of patches is also assumed to be normal as it was observed in the previous part. Mean and variance values were calculated for each window and points outside the probability limits were determined according to the upper and lower limits determined based on mean and standard deviation. For these detected points to be seen more easily in the image, they were changed to black, and a modified version was created. Compared to the visuals of the first one, more out-of-control points could be detected in the window-size approach, which can be attributed to the smaller batches of data utilized in the parameter estimation parts and the decrease in the value of standard deviation compared to the dataset as a whole. Although this approach is better at detecting, as the window size gets smaller, the computational burden increases exponentially which creates a trade-off between detection and computational performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](4.png)\n",
    "\n",
    "*Modified image for window-size approach.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](5.png)\n",
    "\n",
    "*Modified image for window-size approach with better visualization via smaller control limits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>- A Simple Defect Detection Approach from a Control Chart Perspective</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Row Based</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was requested to examine the resulting pixel matrix based on each row and each column, find the distribution, and proceed in this way. It was first considered as row-based. To observe in general terms, the first 5 rows were taken into consideration and it was seen that the normality assumption was still maintained. One can be seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](6.png)\n",
    "![karşılaştırma](7.png)\n",
    "\n",
    "*Pixel Value Distribution and Row Mean Control Chart for one of the first 5 rows.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upper and lower control values ​​were obtained by using the 3-sigma value. Using these values, a control chart was created for each row and out-of-control points were painted black. The modified image using the row-based approach can be seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](8.png)\n",
    "\n",
    "*Modified image for row-based approach.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Column Based</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it was considered as column-based. To observe in general terms, the first 5 columns were taken into consideration and it was seen that the normality assumption was still maintained. One can be seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](9.png)\n",
    "![karşılaştırma](10.png)\n",
    "\n",
    "*Pixel Value Distribution and Column Mean Control Charts for one of the first 5 columns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upper and lower control values ​​were obtained by using the 3-sigma value. Using these values, a control chart was created for each column and out-of-control points were painted black. The modified image using the column-based approach can be seen below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](11.png)\n",
    "\n",
    "*Modified image for column-based approach.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all operations are completed separately for columns and rows, it is seen that the detection performed for the row works more successfully. The reason for this is that there is a defect similar to the column shape. Other images may yield different results. It seems that the first approach still gave visually the best results. Although working with row gives better results than column, the best result is still the first result mentioned above.The resulting images are below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](12.png)\n",
    "\n",
    "*Modified images for row-based and column-based approachs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the performance of the approaches, the visually differences which are brightness , contrast or any other details are compared to original. The areas where pixels were modified after implementing approaches are identified. It is checked whether the changes enhance or degrade the image’s appearance. The assumption of normality is used and control limits or any applications are modified according to the assumptions. Las but not least, variation of control limits is used because it is important to keep Type 1 error probability low while determining all the defects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](13.png)\n",
    "\n",
    "*Modified image for row-based approach with 2 sigma limits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](14.png)\n",
    "\n",
    "*Modified image for column-based approach with 2 sigma limits.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>New Proposal</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Gradient Method Implemented</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods in image processing to find edges, determine autocorrelations, and decide on defects or in general abnormalities. Though a number of different techniques and methods that can fit the project’s target largely were examined thoroughly in the project, one of the most striking methods among these is found to be the \"Gradient Method\". Gradient methods such as the Sobel filter or Canny edge detection, are largely used to detect edges or changes in intensity, which can be contemplated as unexpected occurrences or behaviors in the patterns of data and in the scope of defect detection, those edges can be considered as the areas more conducive to include a defect. Gradient methods calculate the change in brightness over the image and can find boundaries or some defects in images. This makes gradients useful in detecting defects in the fabric. Since they are highly sensitive to even small changes and highly robust to inherent variations, they are particularly useful to use while working with small changes.\n",
    "\n",
    "There occurs an important problem in the project which is autocorrelation. Gradient methods can determine differences between normal and defective areas, however, they are not directly good for finding and dealing with autocorrelations. They just make the defects more prominent compared to a uniform background. In this part, there occurs a need to combine with other methods. For reducing the autocorrelations, image processing techniques like subtracting local averages or using high-pass filters might be more directly applicable. High-pass filters like Laplacian or Sobel can determine sudden changes in texture like defects, while reducing the impact of overall texture which are defects in this project. After a set of sobel kernel sizes and row/column traverse operations are exercised on the data with Sobel, it was observed that it is more applicable to use in the project’s targets. \n",
    "\n",
    "In the Sobel filter, increasing the kernel size in edge detection provides a border perspective which results in higher precision at the expense of a larger computational burden. The pixel values and the resulting gradient values for each pixel were so different among each other. The gradient obtained using the Sobel operator is normalized to make data more consistent and conducive to be compared. These methods are particularly effective in situations where the detection of fine details and edges or defects in an image is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](15.png)\n",
    "![karşılaştırma](16.png)\n",
    "\n",
    "*Sobel applied with different kernel sizes and resulted in different precision levels.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](17.png)\n",
    "\n",
    "*Scharr applied.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](18.png)\n",
    "\n",
    "*Distribution of Sobel applied pixels are visualised.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](19.png)\n",
    "\n",
    "*Resulting Sobel matrix used with log-normal assumption.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image processing techniques described above were very important for this project. The importance of kernel size for the Sobel filter was mentioned. Kernel size 3 was purchased and the 'scar' method was tried, but it was inadequate. Setting the kernel size to 7 increased the edge detection sensitivity. Using a larger value such as 9 was avoided because this time the degree of freedom would increase, which would lead to uncertainty. After applying Sobel, various assumptions were tried to determine the statistical distribution. Log-normal was tried in case the normal assumption applied at the beginning of the project did not fit, it was more suitable for the current case. The alpha value was taken as 5 and a higher sensitivity was aimed, but it was not sufficient. The normal assumption was returned. This process was then repeated for each column and row. It was seen more clearly in these experiments that the normal distribution was valid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](20.png)\n",
    "\n",
    "*Resulting Sobel matrix used with normal assumption.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](21.png)\n",
    "\n",
    "*Resulting Sobel matrix used with log-normal assumption.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](22.png)\n",
    "\n",
    "*Resulting Sobel matrix used with normal assumption.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>EWMA Integrated to Gradient Algorithm</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When moved to the next stage, as the first candidate to be practiced in the proposed technique, the EWMA and the gradient algorithms were integrated. This combination aimed to use the advantages of time series analysis in defect detection, particularly the somewhat useful feature of EMWA, that is forgetting the previous values exponentially. Separate control charts were created for each row and defect detection was further refined. In these graphs, UCL and LCL were determined, and out-of-control points were investigated for the first 5 rows to get insights. By adjusting the lambda value, changes were made to the range and deviations of the control charts, aiming for the most appropriate value. When Lambda was very low, it got very hard to detect defective points as the number of defective points skyrocketed since a larger weight is attached to the points that are far away from the current point and the estimation power declined larger. Therefore, a higher valued lambda was used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](23.png)\n",
    "\n",
    "*EWMA applied to rows and the resulting control chart.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](24.png)\n",
    "\n",
    "*EWMA applied to rows and the resulting control chart with smaller lambda value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](25.png)\n",
    "\n",
    "*EWMA applied to all rows.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](26.png)\n",
    "\n",
    "*EWMA applied to all rows with smaller lambda value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](27.png)\n",
    "\n",
    "*EWMA applied to columns and the resulting control chart.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](28.png)\n",
    "\n",
    "*EWMA applied to columns and the resulting control chart with smaller lambda value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](29.png)\n",
    "\n",
    "*EWMA applied to all columns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](30.png)\n",
    "\n",
    "*EWMA applied to all columns with smaller lambda value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>CUSUM Integrated to Gradient</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the CUSUM method was integrated to the Gradient method by using the resulting normalized gradient matrix as a base in the project. To benefit from the cumulative nature of CUSUM, each row and column is traversed once with relatively smaller samples compared to using the flattened resulting matrix as a whole and a separate control is conducted for each step and outliers are detected. As we can now easily observe the change in the pixel values cumulatively for each row, better quality detection is expected and the resulting figures were those with the highest accuracy considering the density of black dots gathered around actual defective points, particularly in the image obtained after rows are traversed. Though the reason why it was not very successful for columns may be related to the image utilized since there is a vertical defect in the group image used. As a result, it was decided to conduct a study by integrating CUSUM and gradient algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](31.png)\n",
    "\n",
    "*CUSUM applied to all rows and columns with gradient.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](32.png)\n",
    "\n",
    "*CUSUM applied to all rows and columns with gradient.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Wavelet Transform</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last candidate, the Wavelet method was also tried since it was largely used in detecting edges and defective points, but good results could not be obtained because the images used were not detailed enough. Wavelet provides more effective results, especially in images with details such as more complex human figures. The simple and low-detailed fabrics used in the project were not useful for this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](33.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](34.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](35.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](36.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](37.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](38.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](39.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Proposal (Normalized Gradient integrated with CUSUM Traversed on Rows and Columns) to detect defects on 5 arbitrarily selected images</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](40.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](41.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](42.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](43.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![karşılaştırma](44.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusion and Results</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images in all stages of the project are transformed to grayscale as requested and the distribution was assumed to be normal for by deducing from the histogram of pixels. Afterwards, with this assumption, a threshold value of 0.001 was determined and continued with this data. The points that were out of control were painted black and observations were made. New attempts by changing the upper and lower bound values ​​were not as successful as the first one. Then a patch based approach was used with windows of size 51x51. Parameters for each window were calculated and o.o.c. points were again painted black. Although this approach works better, as you reduce the window size, the approach will slow down and require more computations, so it would not be preferred. The project continued as requested and this time row and column evaluations started. Distribution is found for each row and each column and o.o.c. points have been determined seperately. When all control charts were drawn and observations were made, a more successful result was obtained for the rows. The important point here is that the defect is considered to be along the column. However, the first method used was still observed to be the most successful in producing results. Differences were visually addressed while performing performance evaluations. These are brightness, contrast or other different attributes. After the approaches are applied, the change takes place, observing the modified places is also suitable for detecting defection. The normality assumption remained valid throughout the entire process. When it comes to the proposal part, it can be observed that important image processing methods are used. The most important of these is the \"Gradient Method\", used to find edges, determine autocorrelations and to decide on defects via calculating brightness changes, aiding in defect identification. However, they are not inherently equipped to handle autocorrelation in fabric texture. To address this, additional techniques like subtracting local averages and high-pass filters are integrated. Among these, the Sobel filter, with adjusted kernel size for broader perspective and precision, has been extensively used. Normalizing gradient values from the Sobel operator enhances consistency, proving effective for detailed defect detection.\n",
    "\n",
    "In this fabric defect detection project, image processing techniques, particularly the Sobel filter, played a key role. The importance of kernel size was highlighted, with a size of 3 proving inadequate and a size of 7 increasing edge detection sensitivity. A larger size of 9 was avoided to prevent increased uncertainty. Post-Sobel application, statistical distribution was analyzed, initially using a normal assumption and then switching to a log-normal distribution for better suitability, but ultimately returning to the normal assumption after insufficient results.\n",
    "\n",
    "The integration of the EWMA algorithm with the gradient method was a significant step, enhancing defect detection through time series analysis advantages. Separate control charts were created for each row, with UCL and LCL established and out-of-control points examined. Adjustments in the lambda value were made for optimal control chart performance, avoiding too low values to prevent uniformity in data.\n",
    "\n",
    "Finally, CUSUM methodology was also incorporated, focusing on row and column analysis, with notable success in row detection but limited effectiveness in columns, potentially due to vertical defects in the fabric. The Wavelet method was experimented with but found ineffective due to the lack of detail in the fabric images, as it typically excels in more complex and detailed images like human figures. The project concluded with a focus on integrating CUSUM and gradient algorithms for defect detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>References</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Reference 1](https://www.lifegivinglinen.com/flax-to-linen-display.html)\n",
    "\n",
    "[Reference 2](https://www.thespruce.com/how-to-grow-flax-plants-5074891)\n",
    "\n",
    "[Reference 3](https://www.researchgate.net/publication/258195909_Monitoring_chenille_yarn_defects_using_image_processing_with_control_charts)\n",
    "\n",
    "[Reference 4](https://www.researchgate.net/publication/285273251_The_application_of_'p'_and_'p-CUSUM'_charts_into_textile_sector_in_the_statistical_quality_control_process)\n",
    "\n",
    "[Reference 5](https://www.researchgate.net/publication/270569030_The_Application_of_Principal_Component_Analysis_to_Boost_The_Performance_of_The_Automated_Fabric_Fault_Detector_And_Classifier)\n",
    "\n",
    "[Reference 6](https://iopscience.iop.org/article/10.1088/1361-6501/ace8afchrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://www.irjet.net/archives/V5/i12/IRJET-V5I12173.pdf)\n",
    "\n",
    "[Reference 7](https://bioimagebook.github.io/chapters/2-processing/5-morph/morph.html#:~:text=Our%20first%20two%20morphological%20operations,of%20the%20kind%20of%20image)\n",
    "\n",
    "[Reference 8](https://www.hindawi.com/journals/scn/2021/9948808/?utm_source=google&utm_medium=cpc&utm_campaign=HDW_MRKT_GBL_SUB_ADWO_PAI_DYNA_SPEC_X_X0000_Nov2023Commissioned&gad_source=1&gclid=Cj0KCQiAwP6sBhDAARIsAPfK_wa9_GOIpSZ52vwfikK-3Q1PWExtlTs7hDf69LsZ9yOeEcw1QAFFJXoaAgQBEALw_wcB)\n",
    "\n",
    "[Reference 9](https://drpress.org/ojs/index.php/ajst/article/view/2985)\n",
    "\n",
    "[Reference 10](https://www.sciencedirect.com/science/article/pii/S1568494623005392)\n",
    "\n",
    "[Reference 11](https://www.internationaljournalcorner.com/index.php/ijird_ojs/article/view/134735)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
